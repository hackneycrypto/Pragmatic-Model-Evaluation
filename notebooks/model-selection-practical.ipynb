{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Selection Practical Notebook\n",
    "\n",
    "In this notebook you will demonstrate what you have learnt in the lesson and tackle the following challenges:\n",
    "\n",
    "1. Write your own \"Randomised Selection\" code to select the optimal configuration for your linear model.\n",
    "2. Modify the `SimpleNeuralNetwork()` code in the lesson notebook such that it runs a classificaiton model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_diabetes, load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes['data']\n",
    "y = diabetes['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q1.** Implement your own Randomised Selection function.\n",
    "\n",
    "Recall that randomised selection is a method to determine the optimal configuration for a linear regression model.\n",
    "\n",
    "_Hint: you would need a sampling function that gives you potential feature candidates, consider using `np.random.choice`. Remember also that AIC and BIC should only be calculated on the training sample, where you may also wish to calculate MSE on the test sample_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AIC and BIC function\n",
    "\n",
    "def AIC(X, y, lm):\n",
    "    \"\"\" Compute the AIC score of a linear model\"\"\"\n",
    "    N = X.shape[0]\n",
    "    y_pred = lm.predict(X)\n",
    "    ll = -(N/2)*np.log(mean_squared_error(y_pred, y))\n",
    "    k = len(lm.coef_)\n",
    "    \n",
    "    return 2*k - 2*ll\n",
    "\n",
    "def BIC(X, y, lm):\n",
    "    \"\"\" Compute the BIC score of a linear model\"\"\"\n",
    "    N = X.shape[0]\n",
    "    y_pred = lm.predict(X)\n",
    "    ll = -(N/2)*np.log(mean_squared_error(y_pred, y))\n",
    "    k = len(lm.coef_)\n",
    "    \n",
    "    return k*np.log(N) - 2*ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal feature configuration according to the AIC is: [0 1 1 1 0 0 1 0 1 1]\n",
      "The optimal feature configuration according to the BIC is: [0 1 1 1 0 1 1 0 1 1]\n",
      "The optimal feature configuration according to the MSE is: [0 0 1 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "\n",
    "def sample_candidates(num_samples, p):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        num_samples: number of samples to sample, if None, returns all possible combinations.\n",
    "        p: number of features\n",
    "    \"\"\"\n",
    "    \n",
    "    all_samples = []\n",
    "    \n",
    "    for i in range(1,2**p):\n",
    "        all_samples.append(np.array(list(np.binary_repr(i, width=p)), dtype=int))\n",
    "    \n",
    "    if num_samples: \n",
    "        indx = list(range(len(all_samples)))\n",
    "        chosen_indx = np.random.choice(indx, size = num_samples)\n",
    "        \n",
    "        return np.array([all_samples[i] for i in chosen_indx]).astype(bool)\n",
    "\n",
    "    else:\n",
    "        return np.array(all_samples).astype(bool)\n",
    "\n",
    "    \n",
    "\n",
    "def return_metric(X_train, y_train, X_test, y_test, candidate, metric=\"aic\"):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        X_train, y_train, X_test, y_test: The standard train-validation test split of your training data.\n",
    "        candidate: Candidate set of features for testing - can take either an array of unique column indexes or boolean array as to whether corresponding column should be included\n",
    "        metric: the metric used to access the goodness of fit. \"aic\", \"bic\" or \"mse\". Note that AIC and BIC are calculated on the training data, whereas MSE is calculated on the test data.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_sub = X_train[:, candidate]\n",
    "    X_test_sub = X_test[:, candidate]\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train_sub, y_train)\n",
    "    \n",
    "    if metric == \"aic\":\n",
    "        return AIC(X_train_sub, y_train, lm)\n",
    "    elif metric == \"bic\":\n",
    "        return BIC(X_train_sub, y_train, lm)\n",
    "    elif metric == \"mse\":\n",
    "        return mean_squared_error(y_test, lm.predict(X_test_sub))\n",
    "\n",
    "\n",
    "def random_selection(X_train, y_train, X_test, y_test, metric, num_samples=None):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        X_train, y_train, X_test, y_test: The standard train-validation test split of your training data.\n",
    "        num_samples: number of samples for the `sample_candidate` function\n",
    "        metric: the metric used to access the goodness of fit. \"aic\" or \"bic\"\n",
    "    \n",
    "    \"\"\"\n",
    "    samples = sample_candidates(num_samples, X_train.shape[1])\n",
    "    metric_ls = []\n",
    "    for candidate in samples:\n",
    "        metric_ls.append(return_metric(X_train, y_train, X_test, y_test, candidate, metric=metric))\n",
    "    \n",
    "    return samples, metric_ls\n",
    "\n",
    "\n",
    "# Demo\n",
    "np.random.seed(42)\n",
    "for metric in ['aic', 'bic', 'mse']:\n",
    "    samples_, metric_ls_ = random_selection(X_train, y_train, X_test, y_test, metric, 30)\n",
    "    best_sample = samples_[np.argmin(metric_ls_)]\n",
    "    print(f\"The optimal feature configuration according to the {metric.upper()} is: {best_sample.astype(int)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Annotation of Q1 Solution\n",
    "\n",
    "### Overview\n",
    "This solution implements a **randomized feature selection algorithm** that searches for the optimal subset of features for linear regression by testing random combinations and evaluating them using AIC, BIC, or MSE.\n",
    "\n",
    "---\n",
    "\n",
    "### Function 1: `sample_candidates(num_samples, p)`\n",
    "\n",
    "**Purpose**: Generate feature subset candidates to test.\n",
    "\n",
    "**Algorithm**:\n",
    "1. **Binary enumeration trick**: Represents each feature combination as a binary number\n",
    "   - For `p=3` features: `101` binary = use features 0 and 2, skip feature 1\n",
    "   - Total combinations: `2^p - 1` (excluding the empty set)\n",
    "\n",
    "2. **Generate all possible combinations**:\n",
    "   ```python\n",
    "   for i in range(1, 2**p):  # Start at 1 to avoid empty feature set\n",
    "       np.binary_repr(i, width=p)  # Convert i to binary string with p digits\n",
    "   ```\n",
    "   - Example: `binary_repr(5, width=4)` → `\"0101\"` → `[0,1,0,1]` → `[False, True, False, True]`\n",
    "\n",
    "3. **Random sampling**:\n",
    "   - If `num_samples` specified: randomly select that many combinations\n",
    "   - If `None`: return all combinations (exhaustive search)\n",
    "\n",
    "**Returns**: Boolean array of shape `(num_samples, p)` where `True` = include feature\n",
    "\n",
    "---\n",
    "\n",
    "### Function 2: `return_metric(X_train, y_train, X_test, y_test, candidate, metric)`\n",
    "\n",
    "**Purpose**: Evaluate a single feature subset using the specified metric.\n",
    "\n",
    "**Steps**:\n",
    "1. **Feature selection**: Use boolean indexing to select only the features indicated by `candidate`\n",
    "   ```python\n",
    "   X_train_sub = X_train[:, candidate]  # Keep only True columns\n",
    "   ```\n",
    "\n",
    "2. **Train model**: Fit `LinearRegression` on the reduced dataset\n",
    "\n",
    "3. **Compute metric**:\n",
    "   - **AIC** (Akaike Information Criterion): `2k - 2LL`\n",
    "     - Balances model fit (log-likelihood) vs complexity (k parameters)\n",
    "     - Computed on **training data**\n",
    "     - Lower is better\n",
    "   \n",
    "   - **BIC** (Bayesian Information Criterion): `k·log(N) - 2LL`\n",
    "     - Similar to AIC but penalizes complexity more heavily\n",
    "     - Computed on **training data**\n",
    "     - Lower is better\n",
    "   \n",
    "   - **MSE** (Mean Squared Error): Average squared prediction errors\n",
    "     - Measures generalization performance\n",
    "     - Computed on **test data**\n",
    "     - Lower is better\n",
    "\n",
    "**Key insight**: AIC/BIC assess model quality during fitting; MSE assesses prediction accuracy on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### Function 3: `random_selection(X_train, y_train, X_test, y_test, metric, num_samples)`\n",
    "\n",
    "**Purpose**: Main orchestrator that performs the randomized search.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Generate `num_samples` random feature subsets using `sample_candidates()`\n",
    "2. Evaluate each subset by calling `return_metric()`\n",
    "3. Store all metric scores in a list\n",
    "4. Return both the candidates and their scores\n",
    "\n",
    "**Returns**: `(samples, metric_ls)` tuple\n",
    "- `samples`: Array of boolean feature combinations tested\n",
    "- `metric_ls`: List of corresponding metric scores\n",
    "\n",
    "**Usage**: Find best configuration with `samples[np.argmin(metric_ls)]`\n",
    "\n",
    "---\n",
    "\n",
    "### Demo Section\n",
    "\n",
    "**What it does**:\n",
    "```python\n",
    "np.random.seed(42)  # Ensures reproducibility\n",
    "```\n",
    "- Tests **30 random** feature combinations (out of 1024 possible for 10 features)\n",
    "- Compares using three different metrics: AIC, BIC, and MSE\n",
    "- Finds the best configuration for each metric\n",
    "- Prints binary array showing which features to include (1 = include, 0 = exclude)\n",
    "\n",
    "**Example output interpretation**:\n",
    "```\n",
    "[1 0 1 1 0 1 0 1 1 0]\n",
    "```\n",
    "Means: Use features 0, 2, 3, 5, 7, 8 (where value is 1)\n",
    "\n",
    "---\n",
    "\n",
    "### Efficiency Analysis\n",
    "\n",
    "| Scenario | Features | Total Combinations | Randomized (30 samples) | Time Savings |\n",
    "|----------|----------|-------------------|------------------------|--------------|\n",
    "| Diabetes | 10 | 1,023 | 30 | ~97% |\n",
    "| Medium | 15 | 32,767 | 30 | ~99.9% |\n",
    "| Large | 20 | 1,048,575 | 30 | ~99.997% |\n",
    "\n",
    "**Conclusion**: Randomized selection makes feature selection tractable for high-dimensional data while still finding near-optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q2.** Modify the regression code in `SimpleNeuralNetwork` into a classification model.\n",
    "\n",
    "_Hint: Modify the `model` object defined in the `.fit()` method and also change the loss function from mean squared loss to binary cross entropy loss._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare binary classfication data\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer['data'], cancer['target'].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Regression code to modify\n",
    "class SimpleNeuralNetwork():\n",
    "\n",
    "    def __init__(self, h1, epoch, verbose=False):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            h1: number of nodes in hidden layer 1\n",
    "            epoch: number of gradient updates\n",
    "        \"\"\"\n",
    "        self.epoch = epoch\n",
    "        self.h1 = h1\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            X, y: predictor and target\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        inputs = torch.from_numpy(X).float()\n",
    "        targets = torch.from_numpy(y).float()\n",
    "\n",
    "        # Create the neural network model\n",
    "        model = torch.nn.Sequential(torch.nn.Linear(p, self.h1),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.Linear(self.h1, 1))\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "        for rd in range(self.epoch):\n",
    "            pred = model(inputs)\n",
    "            loss = loss_fn(pred, targets)\n",
    "\n",
    "            if rd%300 == 0:\n",
    "                print(\"loss: %.2f\" %loss)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        inputs = torch.from_numpy(x_test).float()\n",
    "        return self.model(inputs).data.numpy()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
